{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sim: S1XT33N Integration/Final Demo\n",
    "\n",
    "### EECS 16B: Designing Information Devices and Systems II, Summer 2022\n",
    "\n",
    "\n",
    "Written by Nathaniel Mailoa and Emily Naviasky (2016)\n",
    "\n",
    "nmailoa@berkeley.edu &emsp; enaviasky@berkeley.edu\n",
    "\n",
    "Updated by Zhongkai Wang (2021) &emsp; Bozhi Yin (2021, 2022)\n",
    "\n",
    "zhongkai@berkeley.edu &emsp; bozhi_yin@berkeley.edu\n",
    "\n",
    "Updated by Mingyang Wang (2022)\n",
    "\n",
    "quackquack@berkeley.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "* [Part 0. Introduction](#intro)\n",
    "* [Part 1. Integration](#part1)\n",
    "* [Part 2. Play with your car](#part2)\n",
    "* [Part 3. Final Demo](#part3)\n",
    "* [Part 4. Checkoff](#part4)\n",
    "* [Part 5. Final Lab Report](#part5)\n",
    "\n",
    "## <span style=\"color:#ba190f\"> You need to run the Python scripts one by one, or errors will show up as they rely on the variables defined sequentially!!\n",
    "\n",
    "## <span style=\"color:#ba190f\"> DO NOT include units when submitting your answers on Gradescope! ONLY include the numerical value rounded to the number of decimal places specified in each question, in the units specified in the question. DO NOT include letters, words, etc. If a question involves entering an answer that is not a numerical value, the format of the answer will be clearly specified in that question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## <span style=\"color:blue\"> Part 0. Introduction\n",
    "\n",
    "Now you are on your last steps! SIXT33N has slowly been taking shape and soon, it will be running around causing trouble. All you need to do now is put everything together in a single Arduino program. The objective is to get SIXT33N to **drive far, drive left, drive close, and drive right** when it hears the corresponding four commands (words).\n",
    "\n",
    "For checkoff in this Integration phase of the project, you need to\n",
    "\n",
    "- Answer the Gradescope questions.\n",
    "- Complete the final demo assignment. Please read Part 3 of the notebook for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part1'></a>\n",
    "## <span style=\"color:blue\"> Part 1. Integration</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Materials\n",
    "- SIXT33N Module in TinkerCAD\n",
    "Model Link to be used in the entire lab: [TinkerCAD Model](https://www.tinkercad.com/things/4hnFnuS4HBR) \n",
    "- Closed-loop control and turning schemes\n",
    "- PCA classifier scheme\n",
    "\n",
    "Everything you work on in this phase will be in the sketch `integration.ino`, which is your final Arduino code for SIXT33N. As we go through it, fill in sections labelled `YOUR CODE HERE` as instructed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wheel Control \n",
    "\n",
    "In the main body of the sketch, the code defines 2 modes: `MODE_LISTEN` and `MODE_DRIVE`. \n",
    "\n",
    "- Replace ... in `CODE BLOCK CON1/2/3` with your code in `turning.ino` from the Advanced Controls lab.\n",
    "\n",
    "### Enveloping and PCA Vectors\n",
    "\n",
    "In `MODE_LISTEN`, the SIXT33N processes your voice data vector `word_array` and tries to classify the word. The Arduino will run classification on the processed snippet to figure out the command. If the Arduino sucessfully classifies a word, then it will enter `MODE_DRIVE`.\n",
    "\n",
    "- We provide you with a `golden` example including PCA vectors and test data to finish Part 1. You do **NOT** need to change anything in `CODE BLOCK PCA1/2` for now.\n",
    "\n",
    "### Classification\n",
    "\n",
    "Next, go to the section labeled `CODE BLOCK PCA3` in the `loop()` function, and copy the code from `classify.ino`. \n",
    "\n",
    "- This block should do the PCA projection and classification. \n",
    "- **Please note that the code used for projecting data vectors onto the new basis has already been filled in for you.** You only need to replace `...` with your code from `classify.ino`.\n",
    "\n",
    "\n",
    "###  Driving\n",
    "\n",
    "`word_array`, in `CODE BLOCK PCA2`, defines a serial of commands controlling SIXT33N. The given `word_array` is a recording of someone saying the 4 words in order and converted using the get_snippets code. It controls the car to `drive far`, `drive left`, `drive close`, and `drive right`, with four commands in the following order: **word1, word2, word3, and word4**. \n",
    "\n",
    "- Remember to change the parameter `NUM_COMMANDS` when you change the number of commands.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! You should be set. Now load the sketch into TinkerCad and run the simulation. The serial monitor will plot two waveforms in the serial plotter just as like in the Advanced Controls phase. You can see that:\n",
    " - The blue curve corresponds to the x-position of the car, and the orange line corresponds to the y-position of the car. \n",
    " - After finishing the plot, the serial monitor also prints out the positions after each command. With four commands, we would have five positions by including the initial position (0, 0).\n",
    "\n",
    "<img width=800px src=\"images/serial_plot_curve.png\">\n",
    "\n",
    "Now set **mode=1** on line 50 to enter the data collection mode and rerun the simulation. You should get output like the following figure:\n",
    "\n",
    "<img width=800px src=\"images/serial_plot_data.png\">\n",
    "\n",
    "Finally, copy the data from the serial monitor to `trajectory.txt`, and run the following code, which plots the trajectory of SIXT33N. For example, the following plot shows four commands: **drive far, drive left, drive close and drive right**.\n",
    "\n",
    "<img width=400px src=\"images/serial_plot_traj.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import csv\n",
    "import utils\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "utils.plot_car_traj('trajectory.txt', ('DRIVE_FAR', 'DRIVE_LEFT', 'DRIVE_CLOSE', 'DRIVE_RIGHT'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "### Please use the output of serial monitor when `mode=0`  to answer the following questions.\n",
    "\n",
    "<span style=\"color:#075a04\"> **1. With the given command array, what is the final value of the X position of the car? <span style=\"color:#ba190f\">Enter a numerical value with two decimal places (e.g. 3.14).**\n",
    "    \n",
    "< YOU ANSWER ON GRADESCOPE > \n",
    "    \n",
    "    \n",
    "<span style=\"color:#075a04\"> **2. In the same case as Q1, what is the final value of the Y position of the car? <span style=\"color:#ba190f\">Enter a numerical value with two decimal places (e.g. 3.14).**\n",
    "\n",
    "< YOUR ANSWER ON GRADESCOPE > \n",
    "    \n",
    "    \n",
    "<span style=\"color:#075a04\"> **3. What's the distance the car travels under command drive_far? <span style=\"color:#ba190f\">Enter a numerical value with two decimal places (e.g. 3.14).**\n",
    "\n",
    "< YOUR ANSWER ON GRADESCOPE > \n",
    "\n",
    "<span style=\"color:#075a04\"> **4. What's the distance the car travels under command drive_close? <span style=\"color:#ba190f\">Enter a numerical value with two decimal places (e.g. 3.14).**\n",
    "    \n",
    "< YOUR ANSWER ON GRADESCOPE > \n",
    "    \n",
    "<span style=\"color:#075a04\"> **5. What's the average turning radius of commands drive_left and drive_right? Hint: Calculate from the car positions after each command. <span style=\"color:#ba190f\">Enter a numerical value with two decimal places (e.g. 3.14).**\n",
    "\n",
    "< YOUR ANSWER ON GRADESCOPE > \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part2'></a>\n",
    "## <span style=\"color:blue\">Part 2. Play with your car</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Record your own voice commands sequence\n",
    "<a id='part2.1'></a>\n",
    "**Use the next section to record your own test commands (four words in the sequence of \"word2, word1, word4, word3\") and process it using the following code. The last part of the code formats the audio vector ready to be copied and pasted into TinkerCAD to initialize the `word_array`.**\n",
    "\n",
    "\n",
    "You are going to **record your own `wav` files with the four words you chose in the SVD/PCA lab.** \n",
    "\n",
    "\"Good\" audio data has a high signal-to-noise ratio. Recording words while far away from the microphone may cause your intended word to blend in with background noise. However \"oversaturation\" of the audio signal (speaking too loudly and/or too closely into the mic) will distort the signal. \n",
    "\n",
    "To record your own `wav` files, we suggest you use the [online recorder](https://online-voice-recorder.com). \n",
    "\n",
    "**Do the following to record 4 voice commands:**\n",
    "1. Click on record button on the webpage, and come back to this page. \n",
    "2. **Run the following script, when you see the number appear, say the word you want to record.**\n",
    "    - The recording window is 2 seconds. You want to finish the word in this period.\n",
    "    - **Pronounce the word consistently.** This will help you collect data that is less \"noisy\" which will result in better classification.\n",
    "    \n",
    "    \n",
    "3. Once you've recorded the word, the script will stop automatically. **Then go back to the webpage and stop the recording.** You should get a webpage like the following:\n",
    "\n",
    "<center>\n",
    "<img width=\"800px\" src=\"images/recording_8s.png\">\n",
    "</center>\n",
    "\n",
    "4. Change the start time to be near your sample and near the end time. **You want to remove the noise before and after the sample.** The total recording time should be around 8 seconds.\n",
    "\n",
    "5. When you save the file, it is of the `mp3` type. Use the [audio converter](https://online-audio-converter.com) to convert it to a `wav` file with the options shown below.\n",
    "\n",
    "<center>\n",
    "<img width=\"600px\" src=\"images/convert_to_wav.png\">\n",
    "</center>\n",
    "\n",
    "If you cannot get access to the website, you can record with your phone. But you need to convert it to a `wav` file and also clip it to remove the noise signals before the first sample and after the last sample. Another website to convert the audio files is [Audio Converter](https://www.freeconvert.com/audio-converter) and the website to trim the `wav` file is [mp3cutter](https://www.mp3cutter.com). You can also find other useful websites to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = 4        # number of voice commands\n",
    "record_time = 2   # record time for each sample of the word: \n",
    "\n",
    "utils.recording_timer(counts, record_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Generate command vector `word_array` for Arduino\n",
    "<a id='part2.2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "\n",
    "def get_snippets(data, length, pre_length, threshold):\n",
    "    \"\"\"Attempts to align audio samples in data.\n",
    "    \n",
    "    Args:\n",
    "        data (np.ndarray): Matrix where each row corresponds to a recording's audio samples.\n",
    "        length (int): The length of each aligned audio snippet.\n",
    "        pre_length (int): The number of samples to include before the threshold is first crossed.\n",
    "        threshold (float): Used to find the start of the speech command. The speech command begins where the\n",
    "            magnitude of the audio sample is greater than (threshold * max(samples)).\n",
    "    \n",
    "    Returns:\n",
    "        Matrix of aligned recordings.\n",
    "    \"\"\"\n",
    "    assert isinstance(data, np.ndarray) and len(data.shape) == 2, \"'data' must be a 2D matrix\"\n",
    "    assert isinstance(length, int) and length > 0, \"'length' of snippet must be an integer greater than 0\"\n",
    "    assert 0 <= threshold <= 1, \"'threshold' must be between 0 and 1\"\n",
    "    snippets = []\n",
    "\n",
    "    # Iterate over the rows in data\n",
    "    for recording in data:\n",
    "        # Find the threshold\n",
    "        recording_threshold = threshold * np.max(recording)\n",
    "\n",
    "        # Figure out when interesting snippet starts\n",
    "        i = pre_length\n",
    "        while recording[i] < recording_threshold:\n",
    "            i += 1\n",
    "            \n",
    "        snippet_start = min(i - pre_length, len(recording) - length)\n",
    "        snippet = recording[snippet_start:snippet_start + length]\n",
    "\n",
    "        # Normalization\n",
    "        snippet = snippet / np.sum(snippet) * 10000\n",
    "        snippet = snippet.astype(int)\n",
    "        \n",
    "        snippets.append(snippet)\n",
    "\n",
    "    return np.vstack(snippets)\n",
    "\n",
    "\n",
    "# Load data from wav\n",
    "# Replace ... with the path to your WAV file.\n",
    "word_raw_test = utils.read_wav(\"...\", counts)\n",
    "\n",
    "\n",
    "# Get snippets\n",
    "length = 40      # Should be the value you used in SVD/PCA lab\n",
    "pre_length = 5   # Should be the value you used in SVD/PCA lab\n",
    "threshold = 0.5  # Should be the value you used in SVD/PCA lab\n",
    "\n",
    "word_processed_test = get_snippets(word_raw_test, length, pre_length, threshold)\n",
    "print(word_processed_test.shape)\n",
    "\n",
    "word_array = '={'\n",
    "v = word_processed_test[0,:]\n",
    "i = 0\n",
    "\n",
    "for i in range(len(word_processed_test[:,0])):\n",
    "    for j in word_processed_test[i,:].T:\n",
    "        word_array += str(j) + ', '\n",
    "word_array = word_array[:-2]+\"};\"\n",
    "print(\"word_array\")\n",
    "print(word_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Simulate your car on TinkerCAD\n",
    "<a id='part2.3'></a>\n",
    "**Now. you have your own test data for classification:**\n",
    "- Copy and overwrite `word_array` in `CODE BLOCK PCA2`\n",
    "- Update other variables (PCA vectors, centroids, etc.) in `CODE BLOCK PCA1` and `CODE BLOCK PCA2` with your code from `classify.ino`\n",
    "\n",
    "**Set `mode=0` on line 50 and run the simulation again:**\n",
    "- If the Arduino does not classify as well as you think it should, remember to play with the variable `EUCLIDEAN_THRESHOLD` or record voice commands again. Here are several suggestions that might help:\n",
    "    - Make sure the classification accuracy of all words is larger than 80% in your PCA lab. If not, propose new words and redo PCA lab until achieving this accuracy level;\n",
    "    - Listen to the voice you recorded in the PCA lab, try to record them at the same speed and voice level;\n",
    "    - During recording, try to speak words in the middle of the 2s window;\n",
    "    - Make sure that the length, pre-length, and threshold used in this lab are the same as the ones you used in the PCA lab.\n",
    "- If it works as you expect, then it's time to celebrate!\n",
    "\n",
    "**You can also plot the trajectory of the car by setting `mode=1`, collecting and saving data to `trajectory_q6.txt`, and running the following code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_car_traj('trajectory_q6.txt', ('DRIVE_LEFT', 'DRIVE_FAR', 'DRIVE_RIGHT', 'DRIVE_CLOSE'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "### Please use the output of serial monitor when `mode=0`  to answer the following questions.\n",
    "\n",
    "<span style=\"color:#075a04\"> **6. With your own voice commands, what is the final value of the X position of the car? <span style=\"color:#ba190f\">Enter a numerical value with two decimal places (e.g. 3.14).**\n",
    "    \n",
    "< YOU ANSWER ON GRADESCOPE > \n",
    "    \n",
    "    \n",
    "<span style=\"color:#075a04\"> **7. In the same case as Q6, what is the final value of the Y position of the car? <span style=\"color:#ba190f\">Enter a numerical value with two decimal places (e.g. 3.14).**\n",
    "\n",
    "< YOUR ANSWER ON GRADESCOPE > \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Reach the target location\n",
    "<a id='part2.2'></a>\n",
    "Based on the movement trajectories of the car under four different commands, please propose the required sequence of commands (number of commands $\\leq5$) if we want the car to travel from the original point (x=0, y=0) to the target location **(x=21.81, y=-17.87)** with $\\pm10\\%$ tolerance range. And then record the voice commands and verify them with the TinkerCAD simulation.\n",
    "What you need to do are:\n",
    "- Based on the info you got from Questions 3-5, propose a sequence of commands (e.g. DRIVE_RIGHT, DRIVE_FAR, etc.) to let the car reach the target location.\n",
    "- Redo [Part 2.1](#part2.1) to record your voice commands. \n",
    "    - Don't forget to change `counts` to the required number of commands you come up with before recording.\n",
    "- Redo [Part 2.2](#part2.2) to generate a new command vector `word_array`.\n",
    "    - Don't forget to change the path of the .wav file.\n",
    "- Redo [Part 2.3](#part2.3) to simulate your car with the new command vector.\n",
    "    - Don't forget to change `NUM_COMMANDS` on line 44 to the required number of commands you come up with before simulation.\n",
    "    - Set `mode=0` on line 50 to check if the commands are classified correctly.\n",
    "- Set `mode=1`, rerun simulation, and collect and save data to `trajectory_demo.txt`. Plot the trajectory of the car with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace ... with commands sequence your proposed. (e.g. 'DRIVE_RIGHT', 'DRIVE_FAR', etc.)\n",
    "utils.plot_car_traj_wi_target('trajectory_demo.txt', (...))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part3'></a>\n",
    "## <span style=\"color:blue\">Part 3. Final Demo</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Demo\n",
    "\n",
    "- Submit the following results from Part 2.4:\n",
    "    - Proposed commands\n",
    "    - Screenshot of the TinkerCAD simulation when `mode=0` like the one we provided before\n",
    "    - Trajectory plotted with the given script\n",
    "- Submit two figures of **centroids** with **your own training data set** and **your own test data set** plotted in the SVD/PCA (Classification) phase as shown below. **<span style=\"color:#ba190f\"> Warning: You will get 0 points if you submit the figures of our given data set.**\n",
    "    \n",
    "<img width=900px src=\"images/pca_plots.png\">\n",
    "\n",
    "### Video Submission (Optional)\n",
    "\n",
    "If you would like to video tape your final project, feel free to upload it to your Google Drive and share it with us! You will get **1 extra credit global course point** and may even be spotlighted by the EECS Department :D\n",
    "- Start by introducing your group, and explain your words/commands.\n",
    "- Submit the link to the video to Gradescope. Make sure to enable view permissions using the link for all Berkeley accounts!\n",
    "- **See the Integration/Final Demo Piazza post for more details about video structure and submission guidelines.**\n",
    "\n",
    "Congratulations - you're done! If you have some time, be creative and try to add a functionality to the SIXT33N car! **Don't forget about our TI Design Contest, where you can get extra credit global course points and prizes from TI!** Please see Piazza for more contest details. You can join a hands-on lab group with hardware. Also, don't hesitate to ask for your GSI's help if you want to modify the Arduino sketch since it is a bit more complicated than previous sketches.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part4'></a>\n",
    "## <span style=\"color:blue\">Part 4: CHECKOFF</span>\n",
    "-----\n",
    "\n",
    "### For sim students, submit your answers to Integration Questions 1-7 to the Gradescope assignment \"Integration.\" Submit the final demo to the Gradescope assignment \"Final Demo.\" Each is worth 50% of your Integration/Final Demo lab grade. Both assignments are due on Sunday, August 7 at 11:59pm. No late submissions will be accepted.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part5'></a>\n",
    "## <span style=\"color:blue\">Part 5. Final Lab Report</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In addition to the final demo, you will also need to submit a final lab report (linked on Piazza and course website).** Individually or in groups of 2, briefly summarize each 16B lab, elaborate on your design choices, and answer all the questions specified in the document.\n",
    "\n",
    "**Submit the report as a PDF to Gradescope by Saturday, August 13 at 11:59 PM. Please read all the instructions clearly in the report document and read the Final Lab Report Piazza post for very important lab report details.**\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
